{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of FineTuneBert Feature Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aLoPn09Xb3WB"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E0ap7X1OPZE"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBlk2dHKOSty"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUksdPsmWJrs"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVQB4X8rOWNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e619c16-a961-441b-a6f2-642ce7528a66"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/dataset/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJGhFFs1OYBQ"
      },
      "source": [
        "df_train = pd.read_json('all_train_small.json.gz', compression='gzip', lines=True)\n",
        "#df_train = pd.read_json('all_train_medium.json.gz', compression='gzip', lines=True)\n",
        "#df_train = pd.read_json('all_train_large.json.gz', compression='gzip', lines=True)\n",
        "#df_train = pd.read_json('all_train_xlarge.json.gz', compression='gzip', lines=True)\n",
        "valid = pd.read_csv('all_valid_small.csv')\n",
        "#valid = pd.read_csv('all_valid_medium.csv')\n",
        "#valid = pd.read_csv('all_valid_large.csv')\n",
        "#valid = pd.read_csv('all_valid_xlarge.csv')\n",
        "df_test = pd.read_json('task1_testset_1500_with_labels.json.gz', compression='gzip', lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TPbpz3XOeHT",
        "outputId": "e23de0b9-5e71-4f60-f4d6-4752e2dfc756"
      },
      "source": [
        "val = valid['pair_id'].tolist()\n",
        "df_valid = df_train[df_train.pair_id.isin(val)]\n",
        "df_valid.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1808, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8Qqo6YVOfzd",
        "outputId": "daf6ec52-0646-4bb9-aec3-ab7c431f657c"
      },
      "source": [
        "print('Original Shape of df_train : ', df_train.shape)\n",
        "val = valid['pair_id'].tolist()\n",
        "df_train = df_train[~df_train.pair_id.isin(val)]\n",
        "print('Shape of df_train (after removal validate) : ', df_train.shape)\n",
        "test = df_test['pair_id'].tolist()\n",
        "df_train = df_train[~df_train.pair_id.isin(test)]\n",
        "print('Shape of df_train (after removal test) : ', df_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Shape of df_train :  (9038, 22)\n",
            "Shape of df_train (after removal validate) :  (7230, 22)\n",
            "Shape of df_train (after removal test) :  (7230, 22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brY1vfqVOm2r"
      },
      "source": [
        "df_train['description_left'] = df_train['description_left'].fillna('')\n",
        "df_train['description_right'] = df_train['description_right'].fillna('')\n",
        "df_train['left_temp'] = df_train['description_left']\n",
        "#df_train['left_temp'] = df_train['title_left'] + df_train['description_left']\n",
        "df_train['right_temp'] = df_train['description_right']\n",
        "#df_train['right_temp'] = df_train['title_right'] + df_train['description_right']\n",
        "df_train = df_train.replace(r'\\n',' ', regex=True) \n",
        "df_train = df_train.replace(r'\\\\n',' ', regex=True)\n",
        "df_train = df_train.replace(r'\\t',' ', regex=True) \n",
        "df_train = df_train.loc[:, ['left_temp', 'right_temp', 'label']]\n",
        "df_train.columns = ['text_a', 'text_b', 'label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi2TtCdIOnaC"
      },
      "source": [
        "df_valid['description_left'] = df_valid['description_left'].fillna('')\n",
        "df_valid['description_right'] = df_valid['description_right'].fillna('')\n",
        "df_valid['left_temp'] = df_valid['description_left']\n",
        "#df_valid['left_temp'] = df_valid['title_left'] + df_valid['description_left']\n",
        "df_valid['right_temp'] = df_valid['description_right']\n",
        "#df_valid['right_temp'] = df_valid'title_right'] + df_valid['description_right']\n",
        "df_valid = df_valid.replace(r'\\n',' ', regex=True) \n",
        "df_valid = df_valid.replace(r'\\\\n',' ', regex=True)\n",
        "df_valid = df_valid.replace(r'\\t',' ', regex=True) \n",
        "df_valid = df_valid.loc[:, ['left_temp', 'right_temp', 'label']]\n",
        "df_valid.columns = ['text_a', 'text_b', 'label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FrWkhxKOotC"
      },
      "source": [
        "df_test['description_left'] = df_test['description_left'].fillna('')\n",
        "df_test['description_right'] = df_test['description_right'].fillna('')\n",
        "df_test['left_temp'] = df_test['description_left']\n",
        "#df_test['left_temp'] = df_test['title_left'] + df_test['description_left']\n",
        "df_test['right_temp'] = df_test['description_right']\n",
        "#df_test['right_temp'] = df_test['title_right'] + df_test['description_right']\n",
        "df_test = df_test.replace(r'\\n',' ', regex=True) \n",
        "df_test = df_test.replace(r'\\\\n',' ', regex=True)\n",
        "df_test = df_test.replace(r'\\t',' ', regex=True) \n",
        "df_test = df_test.loc[:, ['left_temp', 'right_temp', 'label']]\n",
        "df_test.columns = ['text_a', 'text_b', 'label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOAx7lTmqEY-"
      },
      "source": [
        "#df_train = df_train[:15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5TF76hePxj6"
      },
      "source": [
        "**Import BERT-base pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li66dqSGbEU3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLNKG0F_Py8x",
        "outputId": "9419c2b7-cc10-484a-f561-d0227b6e7052"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "#bert = AutoModel.from_pretrained('bert-base-uncased',return_dict=False)\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "#bert = AutoModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "#bert.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "o05c0v0JtQj4",
        "outputId": "abcc4b9c-b3df-480e-fafa-64f92aa6b0c2"
      },
      "source": [
        "'''\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig;\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased');\n",
        "\n",
        "bert = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig;\\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased');\\n\\nbert = BertForSequenceClassification.from_pretrained('bert-base-uncased')\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddxvmZlScsJ6"
      },
      "source": [
        "# push the model to GPU\n",
        "bert = bert.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "uDTGdybOYvIq",
        "outputId": "6a7fff72-ae5d-45e0-ea20-b46f4094c197"
      },
      "source": [
        "df_train.to_csv('train.tsv', sep='\\t', index=False)\n",
        "print(\"No. of Training Samples：\", len(df_train))\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of Training Samples： 7230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>text_b</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Description:StorageWorks Internal Tape Drive ...</td>\n",
              "      <td>\"Description:HP SC40Ge Host Bus Adapter  FIO P...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Description:Sun 73GB 1 10K FCAL Drive for Sto...</td>\n",
              "      <td>\"Description:StorageWorks 300GB 10K Fibre Cha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"DDR4, 2666MHz, CL16, 1.2v, XMP 2.0, Lifetime ...</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"Description:36.4GB Ultra320 3.5-inch SCSI Ho...</td>\n",
              "      <td>\"                                     Long pro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\"      Artikel-Nr.: 3522 027/4700.00          ...</td>\n",
              "      <td>\"         Rétro et épurée, cette montre automa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              text_a  ... label\n",
              "1  \"Description:StorageWorks Internal Tape Drive ...  ...     0\n",
              "2  \"Description:Sun 73GB 1 10K FCAL Drive for Sto...  ...     0\n",
              "3  \"DDR4, 2666MHz, CL16, 1.2v, XMP 2.0, Lifetime ...  ...     1\n",
              "4   \"Description:36.4GB Ultra320 3.5-inch SCSI Ho...  ...     0\n",
              "5  \"      Artikel-Nr.: 3522 027/4700.00          ...  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj2jnwVzYvRI",
        "outputId": "c0894543-a769-499f-ce34-c6bae7c92a85"
      },
      "source": [
        "df_valid.to_csv('valid.tsv', sep='\\t', index=False)\n",
        "print(\"No. of Validate Samples：\", len(df_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of Validate Samples： 1808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "dfss_kC9YvYG",
        "outputId": "fb04d612-f9d0-4e1d-9f86-bb3cee014bfa"
      },
      "source": [
        "df_test.to_csv('test.tsv', sep='\\t', index=False)\n",
        "print(\"No. of Test Samples：\", len(df_test))\n",
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of Test Samples： 1500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>text_b</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Intel's family of adapter, the Intel' Etherne...</td>\n",
              "      <td>\"2 Port Intel E10G42BTDA 10 Gigabit SFP Ethern...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"ZT-P10710B-10P, Core Clock: 1607MHz, Boost Cl...</td>\n",
              "      <td>\"Zotac GeForce GTX 1070 Ti AMP! Extreme Editio...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"TP-Link 54Mbps Pocket-Sized Wireless Print Se...</td>\n",
              "      <td>\"Print servers give businesses the ability to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"Logitech MK550 Wireless Wave Keyboard and Mou...</td>\n",
              "      <td>\"The Logitech MK550 Wireless Wave Keyboard and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>\"  WD Blue PC SSD 500GB SATA III 2.5″ WDS500G1...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              text_a  ... label\n",
              "0  \"Intel's family of adapter, the Intel' Etherne...  ...     1\n",
              "1  \"ZT-P10710B-10P, Core Clock: 1607MHz, Boost Cl...  ...     1\n",
              "2  \"TP-Link 54Mbps Pocket-Sized Wireless Print Se...  ...     1\n",
              "3  \"Logitech MK550 Wireless Wave Keyboard and Mou...  ...     1\n",
              "4                                                     ...     1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX-3mf0gY0M5"
      },
      "source": [
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv_1hu1vmzZO"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(bert.parameters(), lr = 2e-5) # lr 1e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCItm4WHb9Mi"
      },
      "source": [
        "# Begin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qPJu6fbTQ_0"
      },
      "source": [
        "**Tokenize training, validation, test data by using BERT tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKTrYKpla_z7"
      },
      "source": [
        "# encode vs encode plus vs batch encode plus\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ProductDataset(Dataset):\n",
        "\n",
        "  def __init__(self, mode, tokenizer):\n",
        "    assert mode in ['train', 'valid', 'test']\n",
        "    self.mode = mode\n",
        "    self.df = pd.read_csv(mode + '.tsv', sep='\\t').fillna('')\n",
        "    self.len = len(self.df)\n",
        "    self.tokenizer = tokenizer  \n",
        "    self.max_len = 512\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if self.mode == \"test\":\n",
        "      text_a, text_b = self.df.iloc[idx, :2].values\n",
        "      label_tensor = None\n",
        "    else:\n",
        "      text_a, text_b, label = self.df.iloc[idx, :].values\n",
        "      label_tensor = torch.tensor(label)\n",
        "\n",
        "    #encoded_pair = tokenizer.encode_plus(text_a, text_b, return_tensors='pt', add_special_tokens=True, max_length=self.max_len, truncation='longest_first')\n",
        "    #tokens_tensor  = encoded_pair['input_ids'].squeeze(0)  # tensor of token ids\n",
        "    #segments_tensor = encoded_pair['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n",
        "\n",
        "    tok_seq1 = tokenizer.tokenize(text_a)\n",
        "    tok_seq2 = tokenizer.tokenize(text_b)\n",
        "    len1 = len(tok_seq1)\n",
        "    len2 = len(tok_seq2)\n",
        "\n",
        "\n",
        "    if len1 >= 254 and len2 < 254:\n",
        "      length = 254 + 254 - len2\n",
        "      if len1 >= length :\n",
        "        tok_seq1 = tok_seq1[:length]\n",
        "      #print(idx, ' case1', len(tok_seq1),len(tok_seq2))\n",
        "    elif len1 < 254 and len2 >= 254:\n",
        "      length = 254 + 254 - len1\n",
        "      if len2 >= length :\n",
        "        tok_seq2 = tok_seq2[:length]\n",
        "      #print(idx, ' case2', len(tok_seq1),len(tok_seq2))\n",
        "    else:\n",
        "      tok_seq1 = tok_seq1[:254]\n",
        "      tok_seq2 = tok_seq2[:254]\n",
        "      #print(idx,' case3', len(tok_seq1),len(tok_seq2))\n",
        "\n",
        "    input_ids = [tokenizer.cls_token_id]\n",
        "    input_ids += tokenizer.convert_tokens_to_ids(tok_seq1)\n",
        "    input_ids += [tokenizer.sep_token_id]\n",
        "    token_type_ids = [0]*len(input_ids)\n",
        "    input_ids += tokenizer.convert_tokens_to_ids(tok_seq2)\n",
        "    input_ids += [tokenizer.sep_token_id]\n",
        "    token_type_ids += [1]*(len(tok_seq2)+1) \n",
        "    #attention_mask = [1]*len(input_ids)\n",
        "\n",
        "    #https://stackoverflow.com/questions/56360644/pytorch-runtimeerror-expected-tensor-for-argument-1-indices-to-have-scalar-t\n",
        "    tokens_tensor  = torch.Tensor(input_ids).long()  # tensor of token ids\n",
        "    segments_tensor = torch.Tensor(token_type_ids).long() # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n",
        "    return (tokens_tensor, segments_tensor, label_tensor)\n",
        "    \n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "    \n",
        "\n",
        "trainset = ProductDataset('train', tokenizer=tokenizer)\n",
        "validset = ProductDataset('valid', tokenizer=tokenizer)\n",
        "testset = ProductDataset('test', tokenizer=tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vFUYUvzTzkG"
      },
      "source": [
        "**Data Loader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQLXhXoZa_3l"
      },
      "source": [
        "# collate_fn , SequentialSampler\n",
        "\n",
        "\"\"\"\n",
        "BERT will return 4 tensors\n",
        "- tokens_tensors  : (batch_size, max_seq_len_in_batch)\n",
        "- segments_tensors: (batch_size, max_seq_len_in_batch)\n",
        "- masks_tensors   : (batch_size, max_seq_len_in_batch)\n",
        "- label_ids       : (batch_size)\n",
        "\"\"\"\n",
        "\n",
        "from torch.utils.data import DataLoader,RandomSampler, SequentialSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 'samples' which pass to this function is a list，there are 3 tensors\n",
        "# - tokens_tensor\n",
        "# - segments_tensor\n",
        "# - label_tensor\n",
        "# zero padding will be applied on token tensor & segments tensor，and generate a masks tensors\n",
        "def create_mini_batch(samples):\n",
        "  tokens_tensors = [s[0] for s in samples]\n",
        "  segments_tensors = [s[1] for s in samples]\n",
        "    \n",
        "  # handling when there are labels in dataset\n",
        "  if samples[0][2] is not None:\n",
        "    label_ids = torch.stack([s[2] for s in samples])\n",
        "  else:\n",
        "    label_ids = None\n",
        "    \n",
        "  # zero padding\n",
        "  tokens_tensors = pad_sequence(tokens_tensors,batch_first=True)\n",
        "  segments_tensors = pad_sequence(segments_tensors,batch_first=True)\n",
        "  # attention masks will set the as 1 when the tokens_tensors is not zero, BERT will only pay attention to the non-zero tokens\n",
        "  masks_tensors = torch.zeros(tokens_tensors.shape,dtype=torch.long)\n",
        "  masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
        "  return tokens_tensors, masks_tensors, segments_tensors, label_ids\n",
        "\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "#define a batch size\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(trainset)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(validset)\n",
        "\n",
        "train_dataloader = DataLoader(trainset, sampler=train_sampler,batch_size=BATCH_SIZE, \n",
        "                         collate_fn=create_mini_batch)\n",
        "\n",
        "val_dataloader = DataLoader(validset, sampler=val_sampler,batch_size=BATCH_SIZE, \n",
        "                         collate_fn=create_mini_batch)\n",
        "\n",
        "test_dataloader = DataLoader(testset,collate_fn=create_mini_batch)\n",
        "#test_dataloader = DataLoader(testset, batch_size=BATCH_SIZE, collate_fn=create_mini_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyoXg_HUa__D"
      },
      "source": [
        "def features_generation(dataloader):\n",
        "  total_preds = []\n",
        "  with torch.no_grad():  #https://clay-atlas.com/blog/2020/06/16/pytorch-cn-runtimeerror-cuda-out-of-memory/\n",
        "    for step,batch in enumerate(dataloader):\n",
        "\n",
        "      # push the batch to gpu\n",
        "      batch = [r.to(device) for r in batch]\n",
        "      sent_id, mask, segment, label = batch\n",
        "\n",
        "      # clear previously calculated gradients \n",
        "      bert.zero_grad()\n",
        "\n",
        "      # get model predictions for the current batch\n",
        "      #outputs = bert(sent_id, mask, segment)\n",
        "      #hidden_states = outputs[2]\n",
        "      #word_embed = torch.cat([hidden_states[i] for i in [-1,-2,-3,-4]], dim=-1)\n",
        "      #word_embed = torch.stack(hidden_states[-4:]).sum(0)\n",
        "\n",
        "      preds = bert(sent_id, mask, segment)\n",
        "      features = preds[0][:,0,:].cpu().detach().numpy().tolist()\n",
        "      #features = word_embed.cpu().detach().numpy().tolist()\n",
        "\n",
        "      [total_preds.append(i) for i in features]\n",
        "    return total_preds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2jhWrD1n6Wo"
      },
      "source": [
        "test_features = []\n",
        "#word_embedding = []\n",
        "\n",
        "with torch.no_grad():  #https://clay-atlas.com/blog/2020/06/16/pytorch-cn-runtimeerror-cuda-out-of-memory/\n",
        "  for sent_id, segment, mask, label in test_dataloader:\n",
        "    # get model predictions for the current batch\n",
        "    sent_id, mask, segment = sent_id.to(device), mask.to(device), segment.to(device)\n",
        "\n",
        "    preds = bert(sent_id, mask, segment)\n",
        "    features = preds[0][:,0,:].cpu().detach().numpy().tolist()\n",
        "\n",
        "    #outputs = bert(sent_id, mask, segment)\n",
        "    #hidden_states = outputs[2]\n",
        "    #features = [word_embedding.extend(hidden_states[i].cpu().detach().numpy().tolist()) for i in [-1,-2,-3,-4]]\n",
        "    #features = word_embed.cpu().detach().numpy().tolist()\n",
        "\n",
        "    [test_features.append(i) for i in features]\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd3tZSXwjBmd"
      },
      "source": [
        "train_features = features_generation(train_dataloader)\n",
        "val_features = features_generation(val_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb5zo-1zLlmc",
        "outputId": "9fa835cf-3ce0-44b3-8c8d-cbd46fe37c14"
      },
      "source": [
        "#https://stackoverflow.com/questions/17531796/find-the-dimensions-of-a-multidimensional-python-array\n",
        "def dim(a):\n",
        "    if not type(a) == list:\n",
        "        return []\n",
        "    return [len(a)] + dim(a[0])\n",
        "\n",
        "\n",
        "print('df_train dimension: ', dim(train_features))\n",
        "print('df_valid dimension: ', dim(val_features))\n",
        "print('df_test dimension: ', dim(test_features))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_train dimension:  [7230, 768]\n",
            "df_valid dimension:  [1808, 768]\n",
            "df_test dimension:  [1500, 768]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOtbsQXehwbw"
      },
      "source": [
        "def Xy_generation(l,df):\n",
        "  temp_df = pd.DataFrame(l)\n",
        "  df = df.reset_index(drop=True)\n",
        "  df = pd.concat([df, temp_df], axis=1)\n",
        "  y = df['label'].copy()\n",
        "  X = df.drop(['text_a', 'text_b','label'], axis=1)\n",
        "  return X,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JJbD-F2iqHY"
      },
      "source": [
        "X_train , y_train = Xy_generation(train_features,df_train)\n",
        "X_val , y_val = Xy_generation(val_features,df_valid)\n",
        "X_test , y_test = Xy_generation(test_features,df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYu5BEPxCNs_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rijtIA4jXXZw"
      },
      "source": [
        "**Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cr9fiEvXWM4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "04782c8d-f2c2-403f-a0c8-2cb688738df5"
      },
      "source": [
        "def get_confusion_matrix_values(y_test, y_pred):\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    return(cm[0][0], cm[0][1], cm[1][0], cm[1][1])\n",
        "\n",
        "classifiers = {\n",
        "    \"DummyClassifier_stratified\":DummyClassifier(strategy='stratified', random_state=0),    \n",
        "    \"KNeighborsClassifier\":KNeighborsClassifier(3),\n",
        "    \"XGBClassifier\":XGBClassifier(n_estimators=1000, learning_rate=0.1),\n",
        "    \"DecisionTreeClassifier\":DecisionTreeClassifier(),\n",
        "    \"RandomForestClassifier\":RandomForestClassifier(),\n",
        "    \"AdaBoostClassifier\":AdaBoostClassifier(),\n",
        "    \"GradientBoostingClassifier\":GradientBoostingClassifier(),\n",
        "    \"Perceptron\": Perceptron(max_iter=40, eta0=0.1, random_state=1),\n",
        "    \"MLP\": MLPClassifier(),\n",
        "    \"XGBClassifer tuned\": XGBClassifier(colsample_bytree=0.8,\n",
        "                      gamma=0.9,\n",
        "                      max_depth=20,\n",
        "                      min_child_weight=1,\n",
        "                      scale_pos_weight=12,\n",
        "                      subsample=0.9,\n",
        "                      n_estimators=50, \n",
        "                      learning_rate=0.1)\n",
        "}\n",
        "\n",
        "df_results = pd.DataFrame(columns=['model', 'accuracy', 'mae', 'precision',\n",
        "                                   'recall','f1','roc','run_time','tp','fp',\n",
        "                                   'tn','fn'])\n",
        "\n",
        "for key in classifiers:\n",
        "\n",
        "    start_time = time.time()\n",
        "    classifier = classifiers[key]\n",
        "    model = classifier.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "    roc = roc_auc_score(y_test, y_pred)\n",
        "    classification = classification_report(y_test, y_pred, zero_division=0)\n",
        "    run_time = format(round((time.time() - start_time)/60,2))\n",
        "    tp, fp, fn, tn = get_confusion_matrix_values(y_test, y_pred)\n",
        "\n",
        "    row = {'model': key,\n",
        "           'accuracy': accuracy,\n",
        "           'mae': mae,\n",
        "           'precision': precision,\n",
        "           'recall': recall,\n",
        "           'f1': f1,\n",
        "           'roc': roc,\n",
        "           'run_time': run_time,\n",
        "           'tp': tp,\n",
        "           'fp': fp,\n",
        "           'tn': tn,\n",
        "           'fn': fn,\n",
        "          }\n",
        "    df_results = df_results.append(row, ignore_index=True)\n",
        "\n",
        "df_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>mae</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>roc</th>\n",
              "      <th>run_time</th>\n",
              "      <th>tp</th>\n",
              "      <th>fp</th>\n",
              "      <th>tn</th>\n",
              "      <th>fn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DummyClassifier_stratified</td>\n",
              "      <td>0.562000</td>\n",
              "      <td>0.438000</td>\n",
              "      <td>0.330769</td>\n",
              "      <td>0.245714</td>\n",
              "      <td>0.281967</td>\n",
              "      <td>0.489011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>714</td>\n",
              "      <td>261</td>\n",
              "      <td>129</td>\n",
              "      <td>396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.619333</td>\n",
              "      <td>0.380667</td>\n",
              "      <td>0.397321</td>\n",
              "      <td>0.169524</td>\n",
              "      <td>0.237650</td>\n",
              "      <td>0.515531</td>\n",
              "      <td>0.17</td>\n",
              "      <td>840</td>\n",
              "      <td>135</td>\n",
              "      <td>89</td>\n",
              "      <td>436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.640667</td>\n",
              "      <td>0.359333</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.146667</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.526667</td>\n",
              "      <td>4.08</td>\n",
              "      <td>884</td>\n",
              "      <td>91</td>\n",
              "      <td>77</td>\n",
              "      <td>448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.534667</td>\n",
              "      <td>0.465333</td>\n",
              "      <td>0.361156</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.391986</td>\n",
              "      <td>0.510183</td>\n",
              "      <td>0.28</td>\n",
              "      <td>577</td>\n",
              "      <td>398</td>\n",
              "      <td>225</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.076190</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>0.509890</td>\n",
              "      <td>0.44</td>\n",
              "      <td>920</td>\n",
              "      <td>55</td>\n",
              "      <td>40</td>\n",
              "      <td>485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.645333</td>\n",
              "      <td>0.354667</td>\n",
              "      <td>0.474074</td>\n",
              "      <td>0.121905</td>\n",
              "      <td>0.193939</td>\n",
              "      <td>0.524542</td>\n",
              "      <td>0.47</td>\n",
              "      <td>904</td>\n",
              "      <td>71</td>\n",
              "      <td>64</td>\n",
              "      <td>461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.648667</td>\n",
              "      <td>0.351333</td>\n",
              "      <td>0.493421</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.221566</td>\n",
              "      <td>0.531941</td>\n",
              "      <td>2.44</td>\n",
              "      <td>898</td>\n",
              "      <td>77</td>\n",
              "      <td>75</td>\n",
              "      <td>450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Perceptron</td>\n",
              "      <td>0.528667</td>\n",
              "      <td>0.471333</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.435754</td>\n",
              "      <td>0.526667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>520</td>\n",
              "      <td>455</td>\n",
              "      <td>273</td>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MLP</td>\n",
              "      <td>0.589333</td>\n",
              "      <td>0.410667</td>\n",
              "      <td>0.409543</td>\n",
              "      <td>0.392381</td>\n",
              "      <td>0.400778</td>\n",
              "      <td>0.543883</td>\n",
              "      <td>0.52</td>\n",
              "      <td>678</td>\n",
              "      <td>297</td>\n",
              "      <td>206</td>\n",
              "      <td>319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBClassifer tuned</td>\n",
              "      <td>0.591333</td>\n",
              "      <td>0.408667</td>\n",
              "      <td>0.326772</td>\n",
              "      <td>0.158095</td>\n",
              "      <td>0.213094</td>\n",
              "      <td>0.491355</td>\n",
              "      <td>0.98</td>\n",
              "      <td>804</td>\n",
              "      <td>171</td>\n",
              "      <td>83</td>\n",
              "      <td>442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        model  accuracy       mae  ...   fp   tn   fn\n",
              "0  DummyClassifier_stratified  0.562000  0.438000  ...  261  129  396\n",
              "1        KNeighborsClassifier  0.619333  0.380667  ...  135   89  436\n",
              "2               XGBClassifier  0.640667  0.359333  ...   91   77  448\n",
              "3      DecisionTreeClassifier  0.534667  0.465333  ...  398  225  300\n",
              "4      RandomForestClassifier  0.640000  0.360000  ...   55   40  485\n",
              "5          AdaBoostClassifier  0.645333  0.354667  ...   71   64  461\n",
              "6  GradientBoostingClassifier  0.648667  0.351333  ...   77   75  450\n",
              "7                  Perceptron  0.528667  0.471333  ...  455  273  252\n",
              "8                         MLP  0.589333  0.410667  ...  297  206  319\n",
              "9          XGBClassifer tuned  0.591333  0.408667  ...  171   83  442\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "did5Ap1lu3ob"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}